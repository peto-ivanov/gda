{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "RandomForest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "720fa6d0f11b7ec96fc5a2305c253a374b95718251f66e414cba1cc0c6bb49e9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forests\n",
        "Here, we're going to learn how to use Random Forests through the use of the example given in \"An Introduction to Statistical Learning\" but adapted for Python rather than R. If given the chance, I can't recommend this book enough. It's the easier, introductory version of what's often called the \"Bible\" of Machine Learning - \"The Elements of Statistical Learning\""
      ],
      "metadata": {
        "id": "55CvTNrtu2sE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# Import the necessary library and datasets\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.datasets import load_boston\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import mean_squared_error, r2_score\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "data = pd.DataFrame(load_boston().data)\r\n",
        "data.columns = load_boston().feature_names\r\n",
        "data['MEDV'] = load_boston().target"
      ],
      "outputs": [],
      "metadata": {
        "id": "DKq15qbGuuhu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
              "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
              "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
              "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
              "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
              "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  MEDV  \n",
              "0     15.3  396.90   4.98  24.0  \n",
              "1     17.8  396.90   9.14  21.6  \n",
              "2     17.8  392.83   4.03  34.7  \n",
              "3     18.7  394.63   2.94  33.4  \n",
              "4     18.7  396.90   5.33  36.2  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "metadata": {
        "id": "6HP9t861v84b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A description of each of the variables can be seen below:\r\n",
        "- CRIM - per capita crime rate by town\r\n",
        "- ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\r\n",
        "- INDUS - proportion of non-retail business acres per town.\r\n",
        "- CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\r\n",
        "- NOX - nitric oxides concentration (parts per 10 million)\r\n",
        "- RM - average number of rooms per dwelling\r\n",
        "- AGE - proportion of owner-occupied units built prior to 1940\r\n",
        "- DIS - weighted distances to five Boston employment centres\r\n",
        "- RAD - index of accessibility to radial highways\r\n",
        "- TAX - full-value property-tax rate per 10,000 dollars\r\n",
        "- PTRATIO - pupil-teacher ratio by town\r\n",
        "- B - $1000(B_k - 0.63)^2$ where $B_k$ is the proportion of blacks by town\r\n",
        "- LSTAT - % lower status of the population\r\n",
        "- MEDV - Median value of owner-occupied homes in 1000's of dollars"
      ],
      "metadata": {
        "id": "3MIW3gjDwoeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to be using the dataset to predict MEDV."
      ],
      "metadata": {
        "id": "CqQDwS52xJG_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# Using a random state of 42, create a train/test set with a test set ratio of 0.20\r\n",
        "features = [\"CRIM\",\r\n",
        "            \"ZN\",\r\n",
        "            \"INDUS\",\r\n",
        "            \"CHAS\",\r\n",
        "            \"NOX\",\r\n",
        "            \"RM\",\r\n",
        "            \"AGE\",\r\n",
        "            \"DIS\",\r\n",
        "            \"RAD\",\r\n",
        "            \"TAX\",\r\n",
        "            \"PTRATIO\",\r\n",
        "            \"B\",\r\n",
        "            \"LSTAT\"]\r\n",
        "\r\n",
        "target = \"MEDV\"\r\n",
        "\r\n",
        "X = data[features]\r\n",
        "y = data[target]\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "outputs": [],
      "metadata": {
        "id": "fyp1OVF3wAD4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# Fit a Random Forest with the the following hyperparameters:\r\n",
        "# max_samples = 100, max_depth = 10, n_estimators = 100\r\n",
        "\r\n",
        "RF_model = RandomForestRegressor(n_estimators=100, max_samples=100, max_depth=10).fit(X_train, y_train)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4l-RzvIXweqg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Predict on the test set\r\n",
        "y_predict = RF_model.predict(X_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "zImZVZTryHDU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# Calculate both the MSE and the R2 score`\r\n",
        "print(f\"MSE = {mean_squared_error(y_test, y_predict)}\")\r\n",
        "print(f\"R2  = {r2_score(y_test, y_predict)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE = 13.828380662869431\n",
            "R2  = 0.8114323294539748\n"
          ]
        }
      ],
      "metadata": {
        "id": "X1TZb3hQyTct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# Plot the variable importance with the variable importance on the y-axis and the feature names on the x-axis\r\n",
        "# INSERT CODE HERE\r\n",
        "fig, ax = plt.subplots(figsize=(10, 7))\r\n",
        "ax = sns.barplot(x=features, y=RF_model.feature_importances_)\r\n",
        "ax.set_title(\"Feature importance\")\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# What are the two most important variables?\r\n",
        "# - RM - average number of rooms per dwelling\r\n",
        "# - LSTAT - % lower status of the population\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "id": "o0H53rTyzCFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Optimization\n",
        "Now we're going to try to use the optimal hyperparameters of the Random Forest algorithm using Grid Search in addition to cross validation"
      ],
      "metadata": {
        "id": "HpWBBs5F1iDr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "data.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "metadata": {
        "id": "OMG9lSAJ2n5z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "# View all the possible hyperparameters to use\r\n",
        "RF_model.get_params()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'ccp_alpha': 0.0,\n",
              " 'criterion': 'mse',\n",
              " 'max_depth': 10,\n",
              " 'max_features': 'auto',\n",
              " 'max_leaf_nodes': None,\n",
              " 'max_samples': 100,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_impurity_split': None,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 100,\n",
              " 'n_jobs': None,\n",
              " 'oob_score': False,\n",
              " 'random_state': None,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "metadata": {
        "id": "KNGaLH2C1VZ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "# Create the parameter grid for only max_depth, n_estimators (number of trees), max_features (number of features) and max_samples (maximum number of observations)\r\n",
        "param_grid = {\r\n",
        "    'max_depth': list(range(0, 51, 10)),\r\n",
        "    'n_estimators': list(range(60, 161, 20)),\r\n",
        "    'max_features': ['auto', 'sqrt', None],\r\n",
        "    'max_samples': list(range(6, 507, 100))\r\n",
        "}"
      ],
      "outputs": [],
      "metadata": {
        "id": "ECWn00E52C4L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# Initialize a random forest model\r\n",
        "model = RandomForestRegressor()"
      ],
      "outputs": [],
      "metadata": {
        "id": "i9LI3Eui3YkD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "# Perform a grid search using the following parameter list.\r\n",
        "grid_search = GridSearchCV(\r\n",
        "    estimator = model,\r\n",
        "    param_grid = param_grid,\r\n",
        "    cv = 3,\r\n",
        "    n_jobs = -1,\r\n",
        "    verbose = 2\r\n",
        ")\r\n",
        "\r\n",
        "# Fit the model to the data (this may take a couple minutes)\r\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 648 candidates, totalling 1944 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\pivanov\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.45558289 0.45360374 0.49412136 0.49788322 0.463726   0.48769626\n",
            " 0.80644405 0.80419496 0.80103689 0.80206441 0.8056361  0.80616508\n",
            " 0.81145275 0.81195284 0.81074522 0.81310657 0.81092357 0.8145529\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.41263331 0.46099408 0.39833437 0.42943023 0.44413798 0.43387974\n",
            " 0.79526148 0.79896771 0.79775357 0.79704123 0.80175391 0.79474236\n",
            " 0.81997294 0.82001756 0.81599012 0.81539931 0.81649606 0.81589316\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.51029788 0.48364572 0.47256207 0.49254133 0.47996663 0.49850507\n",
            " 0.81265513 0.80243174 0.81266972 0.80437385 0.80713989 0.80978834\n",
            " 0.81071738 0.81123067 0.80710836 0.81576003 0.81140568 0.81822903\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.47054752 0.45605421 0.45736186 0.48914014 0.48850538 0.46781695\n",
            " 0.80205118 0.79883732 0.80570867 0.81436283 0.81096303 0.80008917\n",
            " 0.80849966 0.81211172 0.79977194 0.81366665 0.81822018 0.81384325\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.42663113 0.44318132 0.42854715 0.41745502 0.44546126 0.39817485\n",
            " 0.7861354  0.78583251 0.79116784 0.79023929 0.79826902 0.7972951\n",
            " 0.82322797 0.81461013 0.8112001  0.82809932 0.81634192 0.8198734\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.48506481 0.45968134 0.48293995 0.45126146 0.45622004 0.48216042\n",
            " 0.80475156 0.80640477 0.8013327  0.81054839 0.80844932 0.81114265\n",
            " 0.81408172 0.80375955 0.81085208 0.81034654 0.80980956 0.81081276\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.4602893  0.44206521 0.50031964 0.48348967 0.45997508 0.47621957\n",
            " 0.80087699 0.81028003 0.805516   0.80647458 0.80450829 0.80198955\n",
            " 0.80908883 0.81171001 0.81662832 0.80890318 0.80717556 0.814331\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.45593112 0.43308172 0.42278828 0.43216416 0.42330399 0.43343423\n",
            " 0.7982629  0.79575329 0.7999012  0.79795176 0.79366052 0.78848996\n",
            " 0.81853987 0.81587048 0.82176223 0.81503028 0.81998739 0.81926672\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.39343542 0.49362301 0.48451487 0.48331023 0.49373343 0.49233145\n",
            " 0.80452632 0.79829058 0.80356709 0.80562809 0.80283161 0.81148562\n",
            " 0.80036584 0.80565519 0.8148624  0.80569787 0.80758783 0.81697752\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.47396011 0.46621237 0.464353   0.4780665  0.4817019  0.45390312\n",
            " 0.80519256 0.81276013 0.80300212 0.80337271 0.80744552 0.80997521\n",
            " 0.80810371 0.81287841 0.81258628 0.80382148 0.81360167 0.81625911\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.41249794 0.37910779 0.41705671 0.43561319 0.43851232 0.4041276\n",
            " 0.77292535 0.79233606 0.79434826 0.79441044 0.7906724  0.79613541\n",
            " 0.82653289 0.81126233 0.81871833 0.82260131 0.81817037 0.817336\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.50671501 0.50857537 0.4893139  0.47997489 0.50167739 0.45616165\n",
            " 0.80447313 0.80727874 0.80249937 0.80823824 0.80552095 0.80454464\n",
            " 0.81333003 0.80848597 0.81549761 0.80885942 0.80976135 0.8026097\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.51374958 0.48868075 0.4756022  0.48283326 0.46800568 0.50374999\n",
            " 0.79314019 0.80145841 0.81069177 0.81108726 0.80489126 0.80677916\n",
            " 0.81492572 0.80964133 0.80915762 0.81482501 0.81125544 0.80997119\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.41693471 0.39705385 0.42652586 0.44076309 0.41991527 0.40470609\n",
            " 0.80616018 0.79064418 0.80210358 0.79468998 0.78728514 0.79937311\n",
            " 0.80168914 0.81773864 0.82030425 0.81935279 0.81288744 0.82207154\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.47565565 0.49298289 0.45072    0.46634265 0.49358031 0.48496637\n",
            " 0.79117955 0.8040095  0.8016798  0.80185057 0.80422677 0.80723578\n",
            " 0.80619721 0.81850558 0.81132541 0.81008457 0.80700868 0.81028889\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
              "             param_grid={'max_depth': [0, 10, 20, 30, 40, 50],\n",
              "                         'max_features': ['auto', 'sqrt', None],\n",
              "                         'max_samples': [6, 106, 206, 306, 406, 506],\n",
              "                         'n_estimators': [60, 80, 100, 120, 140, 160]},\n",
              "             verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "metadata": {
        "id": "LzRN1PRz2tKT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "# Output the best parameters\r\n",
        "grid_search.best_params_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 20,\n",
              " 'max_features': 'sqrt',\n",
              " 'max_samples': 206,\n",
              " 'n_estimators': 120}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "metadata": {
        "id": "NqBsg3rz2ufh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "# Using the best parameters, evaluate the MSE and R2 of a new random forest model.\r\n",
        "best_RF_model = RandomForestRegressor(max_depth=20, max_features=\"sqrt\", max_samples=206, n_estimators=120).fit(X_train, y_train)\r\n",
        "\r\n",
        "# Making prediction array\r\n",
        "y_predict = best_RF_model.predict(X_test)\r\n",
        "\r\n",
        "# Calculate both the MSE and the R2 score`\r\n",
        "print(f\"MSE = {mean_squared_error(y_test, y_predict)}\")\r\n",
        "print(f\"R2  = {r2_score(y_test, y_predict)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE = 12.318674655047186\n",
            "R2  = 0.8320191032812805\n"
          ]
        }
      ],
      "metadata": {
        "id": "uX8TQifH30t2"
      }
    }
  ]
}